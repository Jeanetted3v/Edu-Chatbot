csv_path: ./data/excel_syn_data.csv

hybrid_retriever:
  semantic_weight: 0.7
  keyword_weight: 0.3
  top_k: 5
  persist_dir: ./data/embeddings
  collection: syn_data   # Collection name in chromadb, using syn_data for testing

mongodb:
  db_name: syn_db  # Database name in MongoDB
  chat_history_collection: chat_history
  session_collection: sessions
  timeout_hours: 0.1

# for general usage (sentiment analysis, etc.)
llm:
  provider: OpenAI
  model: gpt-4o-mini
  embedding_model: text-embedding-3-small

query_handler:
  llm:
    provider: azure_async  # openai, openai_async, azure, azure_async, google-gla, anthropic
    model_name: gpt-4o-mini # gpt-4o, claude-3-5-sonnet-latest, gemini-2.0-flash, etc
    api_version: 2024-09-01-preview  # for AzureOpenAI
  # or just llm model names: https://ai.pydantic.dev/api/models/base/#pydantic_ai.models.KnownModelName 
  reasoning_model: "openai:gpt-4o"          # "groq:deepseek-r1-distill-qwen-32b"
  handle_query_model: "openai:gpt-4o-mini"  

  
human_agent:
  sentiment_threshold: 0.4
  confidence_threshold: 0.7

msg_analyzer:
  analysis_interval: 5
  min_message_length: 50  # set to a higher value during dev stage
  trigger_patterns:
    urgency: '\b(urgent|asap|emergency|immediately)\b'
    frustration: '\b(frustrated?|annoyed|angry|upset)\b'
    complaint: '\b(terrible|horrible|awful|worst|bad|poor)\b'
    escalation: '\b(supervisor|manager|complaint|escalate)\b'

sentiment_analyzer:
  provider: vader
  llm_validate_threshold: 0.3  # If using LLM validation
  use_llm_validation: false
  default_score: 0.7

api:
  reload: False

defaults:
  - _self_ 
  - sentiment_analyzer_prompts
  - human_agent_prompts
  - query_handler_prompts

